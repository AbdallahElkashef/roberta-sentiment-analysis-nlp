# Product Reviews Sentiment Analysis (Transformer-Based NLP)

### ğŸ“Œ Overview



This project implements a **Transformer-based sentiment analysis system** for large-scale product reviews.

A fine-tuned **RoBERTa** model is used to classify customer reviews into:



* **Negative**
* **Neutral**
* **Positive**



The project covers the **full AI pipeline**:



Data preprocessing



Model fine-tuning



Evaluation using confusion matrix and classification report



CPU-friendly deployment using **Streamlit**



### ğŸš€ Features



Transformer-based sentiment classification (RoBERTa)



Robust text preprocessing for noisy user reviews



Single-review and batch CSV inference



Interactive **Streamlit web application**



CPU-only deployment compatible with **Streamlit Cloud**



Optional AI-powered review summarization using **Google Gemini**



### ğŸ“‚ Project Structure

Product-Reviews-Sentiment-Analysis-Deployment/

â”‚

â”œâ”€â”€ app.py                     # Streamlit application

â”œâ”€â”€ requirements.txt           # Python dependencies

â”œâ”€â”€ config.toml                # Streamlit configuration

â”‚

â”œâ”€â”€ deploy\_bundle/

â”‚   â”œâ”€â”€ model\_bundle\_cpu.pkl   # CPU-compatible model bundle (state\_dict + metadata)

â”‚   â””â”€â”€ tokenizer/             # HuggingFace tokenizer files

â”‚

â””â”€â”€ README.md                  # Project documentation

### 

### ğŸ§  Model Details



**Architecture**: RoBERTa-base



**Task**: 3-class sentiment classification



**Classes**:



* 0 â†’ Negative
* 1 â†’ Neutral
* 2 â†’ Positive



**Max sequence length**: 128



**Frameworks**: PyTorch + HuggingFace Transformers



### ğŸ§ª Evaluation



The model was evaluated on a held-out **test dataset** using:



Accuracy



Precision / Recall / F1-score



Confusion Matrix (visualized as a heatmap)



Most misclassifications occur between **neutral** and **positive**, which is consistent with natural language ambiguity in customer reviews.



### ğŸŒ Deployment (Streamlit)



The model is deployed using Streamlit, providing:



#### ğŸ”¹ Single Review Mode



Input a review text



View predicted sentiment



See cleaned text



Optional AI-generated summary (Gemini)



#### ğŸ”¹ Batch CSV Mode



Upload CSV file



Predict sentiment for all rows



Download results as CSV



### âš™ï¸ Installation \& Local Run

#### 1ï¸âƒ£ Create environment

conda create -n sentiment\_app python=3.10

conda activate sentiment\_app



#### 2ï¸âƒ£ Install dependencies

pip install -r requirements.txt



#### 3ï¸âƒ£ Run Streamlit app

streamlit run app.py



### â˜ï¸ Streamlit Cloud Deployment



Uses **CPU-only** inference



Model bundle is pre-converted from GPU â†’ CPU



Tokenizer is loaded from *deploy\_bundle/tokenizer*





### ğŸ§© Key Insights



Transformer models significantly outperform classical ML approaches for sentiment analysis.



Proper tokenization and label normalization are critical for stability.



CPU-friendly deployment requires **state\_dict-based saving**, not raw GPU pickles.



Streamlit enables fast prototyping of production-ready NLP systems.



### ğŸ”® Future Work



Several extensions can be explored to further enhance the performance, robustness, and applicability of this sentiment analysis system:



#### Fine-Grained Sentiment Classification

The current model performs three-class sentiment classification (positive, neutral, negative). Future work could extend this task to **five-class prediction (1â˜… to 5â˜… ratings)**, enabling a more granular understanding of customer satisfaction and improving usefulness for recommendation and feedback systems.



#### Data Augmentation for Class Imbalance

Although the dataset is large, the neutral class remains underrepresented. A promising direction is to use **pretrained language generation models** to synthesize realistic neutral reviews, helping to balance the dataset and improve model generalization.



#### Evaluation of Larger Transformer Models

Performance could be further improved by experimenting with **larger and more expressive architectures**, such as **RoBERTa-large** or **DeBERTa**, which may capture deeper contextual and semantic relationships in customer reviews.



#### Hybrid Lexiconâ€“Transformer Approaches

Exploring hybrid models that combine **lexicon-based sentiment analyzers (e.g., VADER)** with transformer-based architectures could provide complementary strengths, particularly for handling short, informal, or emotionally nuanced text.



These future directions open opportunities for improving accuracy, interpretability, and scalability, while extending the system toward more advanced real-world sentiment analysis applications.



### ğŸ‘¤ Authors



Abdallah ELKASHEF

Samsung Innovation Campus (SIC) â€“ AI701 Internship

Department of Mechatronics \& Robotics Engineering

